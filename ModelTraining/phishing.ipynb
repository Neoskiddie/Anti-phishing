{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "phishing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is necessary because I'm using old Docker image compiled for different version: https://blog.ml6.eu/serving-decision-forests-with-tensorflow-b447ea4fc81c \n",
        "\n",
        "The `!` sign before commands is for Colab to run the terminal command. Disregard that in normal environment."
      ],
      "metadata": {
        "id": "coU9ZH7RDtQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow -y\n",
        "!pip install tensorflow==2.5.1 tensorflow_decision_forests==0.1.8 pandas wurlitzer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HUjyo_dcDpHO",
        "outputId": "48ed5119-6279-4bcc-9d34-46c0d4dc53fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.8.0\n",
            "Uninstalling tensorflow-2.8.0:\n",
            "  Successfully uninstalled tensorflow-2.8.0\n",
            "Collecting tensorflow==2.5.1\n",
            "  Downloading tensorflow-2.5.1-cp37-cp37m-manylinux2010_x86_64.whl (454.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 454.4 MB 9.0 kB/s \n",
            "\u001b[?25hCollecting tensorflow_decision_forests==0.1.8\n",
            "  Downloading tensorflow_decision_forests-0.1.8-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Collecting wurlitzer\n",
            "  Downloading wurlitzer-3.0.2-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.1) (3.1.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.1) (0.37.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.1) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.1) (1.1.0)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 41.2 MB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.1) (1.15.0)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 38.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.1) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.1) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.1) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.1) (2.8.0)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.1) (3.17.3)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 47.9 MB/s \n",
            "\u001b[?25hCollecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 47.4 MB/s \n",
            "\u001b[?25hCollecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 59.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.1) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.1) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.1) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.1) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.1) (3.3.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.1) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.1) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.1) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.1) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68714 sha256=b42317c99357eb5fde8d8f18304cc2016545813b4cd73f442ac1d2668abdae94\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, keras-nightly, gast, flatbuffers, tensorflow, wurlitzer, tensorflow-decision-forests\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.13.3\n",
            "    Uninstalling wrapt-1.13.3:\n",
            "      Successfully uninstalled wrapt-1.13.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.4.0 grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 numpy-1.19.5 tensorflow-2.5.1 tensorflow-decision-forests-0.1.8 tensorflow-estimator-2.5.0 typing-extensions-3.7.4.3 wrapt-1.12.1 wurlitzer-3.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the phishing URLs file. \n",
        "# It should contain a user agent with username of phishtank, but registration is disabled...\n",
        "# https://phishtank.org/developer_info.php\n",
        "!wget http://data.phishtank.com/data/online-valid.csv -O /tmp/phishingUrls.csv\n",
        "!wget https://raw.githubusercontent.com/shreyagopal/Phishing-Website-Detection-by-Machine-Learning-Techniques/master/DataFiles/1.Benign_list_big_final.csv -O /tmp/legitUrls.csv"
      ],
      "metadata": {
        "id": "XxerlDGqmp5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0992c43a-64be-486d-e3b2-99edf6a82dc6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-07 15:15:39--  http://data.phishtank.com/data/online-valid.csv\n",
            "Resolving data.phishtank.com (data.phishtank.com)... 104.17.177.85, 104.16.101.75, 2606:4700::6811:b155, ...\n",
            "Connecting to data.phishtank.com (data.phishtank.com)|104.17.177.85|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://data.phishtank.com/data/online-valid.csv [following]\n",
            "--2022-03-07 15:15:39--  https://data.phishtank.com/data/online-valid.csv\n",
            "Connecting to data.phishtank.com (data.phishtank.com)|104.17.177.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn.phishtank.com/datadumps/verified_online.csv?Expires=1646666149&Signature=G7Y0ZJdPbPPoU~piZ9RUGriXUc6rglc5P~IPZu~GdxVarNCOkbuPE9ZY7fTWXN3k6wXzewucH8J7KZQKDpiTBt2P6AvS2Ufwo8mH8L1ohd8ML26~-Fxe3lMi2IHT8t1z95jnQL8ijsWjnsQvxR2l7K-OcC7hqbYhHc3fyx8g2t4ak6AlM59iKx4Md~wH8qvnFcnIzny9DrEIwjJ3JrIF60Onms0nTCHVVa9m6poX463GuBC5uamD7uP-C4T4PQss1XEyv00x1vMaCGOezILWZikrOt8~ohJFYo-jnaztDWaEfSlBSfYReL0bI-VAd5g-SPtkbBiQ1VxhmFTAPPMYvQ__&Key-Pair-Id=APKAILB45UG3RB4CSOJA [following]\n",
            "--2022-03-07 15:15:40--  https://cdn.phishtank.com/datadumps/verified_online.csv?Expires=1646666149&Signature=G7Y0ZJdPbPPoU~piZ9RUGriXUc6rglc5P~IPZu~GdxVarNCOkbuPE9ZY7fTWXN3k6wXzewucH8J7KZQKDpiTBt2P6AvS2Ufwo8mH8L1ohd8ML26~-Fxe3lMi2IHT8t1z95jnQL8ijsWjnsQvxR2l7K-OcC7hqbYhHc3fyx8g2t4ak6AlM59iKx4Md~wH8qvnFcnIzny9DrEIwjJ3JrIF60Onms0nTCHVVa9m6poX463GuBC5uamD7uP-C4T4PQss1XEyv00x1vMaCGOezILWZikrOt8~ohJFYo-jnaztDWaEfSlBSfYReL0bI-VAd5g-SPtkbBiQ1VxhmFTAPPMYvQ__&Key-Pair-Id=APKAILB45UG3RB4CSOJA\n",
            "Resolving cdn.phishtank.com (cdn.phishtank.com)... 104.17.177.85, 104.16.101.75, 2606:4700::6811:b155, ...\n",
            "Connecting to cdn.phishtank.com (cdn.phishtank.com)|104.17.177.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘/tmp/phishingUrls.csv’\n",
            "\n",
            "/tmp/phishingUrls.c     [ <=>                ]   1008K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-03-07 15:15:40 (36.4 MB/s) - ‘/tmp/phishingUrls.csv’ saved [1032501]\n",
            "\n",
            "--2022-03-07 15:15:40--  https://raw.githubusercontent.com/shreyagopal/Phishing-Website-Detection-by-Machine-Learning-Techniques/master/DataFiles/1.Benign_list_big_final.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4139474 (3.9M) [text/plain]\n",
            "Saving to: ‘/tmp/legitUrls.csv’\n",
            "\n",
            "/tmp/legitUrls.csv  100%[===================>]   3.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-03-07 15:15:41 (30.0 MB/s) - ‘/tmp/legitUrls.csv’ saved [4139474/4139474]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "\n",
        "# libraries for parsing the URLs\n",
        "import ipaddress\n",
        "from urllib.parse import urlparse,urlencode\n",
        "\n",
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "# should be 2.5.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX2Qvhtb-Jxo",
        "outputId": "c6cf528b-bfdd-4830-9ef2-adf119134791"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Helper libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# libraries for parsing the URLs\n",
        "from urllib.parse import urlparse\n",
        "# https://github.com/Chandni97/PhishDetect/blob/master/extract_feature.py\n",
        "# https://github.com/ESDAUNG/Phishing-URL-Detection/blob/main/Feature_extraction.java\n",
        "# https://github.com/shreyagopal/Phishing-Website-Detection-by-Machine-Learning-Techniques/blob/master/URL%20Feature%20Extraction.ipynb\n",
        "\n",
        "\n",
        "class UrlFeautures():\n",
        "\n",
        "    def __init__(self, url: str):\n",
        "        self.set_feautures_list(url)\n",
        "\n",
        "    def has_ip(self, url):\n",
        "        '''\n",
        "        Code from https://gist.github.com/dfee/6ed3a4b05cfe7a6faf40a2102408d5d8\n",
        "        slightly modified to detect IPv4 on it's own. Because it's enough to detect IPv4 on it's own, the embeded cases were deleted, as they are detected anyway.\n",
        "        https://stackoverflow.com/questions/53497/regular-expression-that-matches-valid-ipv6-addresses\n",
        "        '''\n",
        "        IPV4SEG = r'(?:25[0-5]|(?:2[0-4]|1{0,1}[0-9]){0,1}[0-9])'\n",
        "        IPV4ADDR = r'(?:(?:' + IPV4SEG + r'\\.){3,3}' + IPV4SEG + r')'\n",
        "        IPV6SEG = r'(?:(?:[0-9a-fA-F]){1,4})'\n",
        "        IPV6GROUPS = (\n",
        "            r'(?:' + IPV6SEG + r':){7,7}' + IPV6SEG,\n",
        "            # 1::                                 1:2:3:4:5:6:7::\n",
        "            r'(?:' + IPV6SEG + r':){1,7}:',\n",
        "            # 1::8               1:2:3:4:5:6::8   1:2:3:4:5:6::8\n",
        "            r'(?:' + IPV6SEG + r':){1,6}:' + IPV6SEG,\n",
        "            # 1::7:8             1:2:3:4:5::7:8   1:2:3:4:5::8\n",
        "            r'(?:' + IPV6SEG + r':){1,5}(?::' + IPV6SEG + r'){1,2}',\n",
        "            # 1::6:7:8           1:2:3:4::6:7:8   1:2:3:4::8\n",
        "            r'(?:' + IPV6SEG + r':){1,4}(?::' + IPV6SEG + r'){1,3}',\n",
        "            # 1::5:6:7:8         1:2:3::5:6:7:8   1:2:3::8\n",
        "            r'(?:' + IPV6SEG + r':){1,3}(?::' + IPV6SEG + r'){1,4}',\n",
        "            # 1::4:5:6:7:8       1:2::4:5:6:7:8   1:2::8\n",
        "            r'(?:' + IPV6SEG + r':){1,2}(?::' + IPV6SEG + r'){1,5}',\n",
        "            # 1::3:4:5:6:7:8     1::3:4:5:6:7:8   1::8\n",
        "            IPV6SEG + r':(?:(?::' + IPV6SEG + r'){1,6})',\n",
        "            # ::2:3:4:5:6:7:8    ::2:3:4:5:6:7:8  ::8       ::\n",
        "            r':(?:(?::' + IPV6SEG + r'){1,7}|:)',\n",
        "            # fe80::7:8%eth0     fe80::7:8%1  (link-local IPv6 addresses with zone index)\n",
        "            r'fe80:(?::' + IPV6SEG + r'){0,4}%[0-9a-zA-Z]{1,}',\n",
        "            IPV4ADDR\n",
        "        )\n",
        "        # Reverse rows for greedy match\n",
        "        IPV6ADDR = '|'.join(['(?:{})'.format(g) for g in IPV6GROUPS[::-1]])\n",
        "        match = re.search(IPV6ADDR, url)  # Ipv6\n",
        "        if match:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def is_url_short(self, url):\n",
        "        \"\"\"Simple method that does regex search for a list of URL shortening domains\n",
        "        The basic list was taken from https://github.com/Chandni97/PhishDetect/blob/master/extract_feature.py\n",
        "        combined with list from https://meta.stackoverflow.com/questions/313621/blacklist-the-use-of-common-link-shorteners-in-posts\n",
        "        there are likely duplicates form both lists\"\"\"\n",
        "        match = re.search(\n",
        "            'zi\\.mu|zi\\.ma|yhoo\\.it|yfrog\\.com|yep\\.it|y\\.ahoo\\.it|xurl\\.es|xrl\\.us|'\n",
        "            'xrl\\.in|wp\\.me|url\\.ie|url\\.co\\.uk|url\\.az|ur1\\.ca|u\\.nu|twurl\\.nl|twurl\\.cc|'\n",
        "            'tr\\.im|to\\.ly|tnij\\.org|tinyurl\\.com|tinylink\\.in|tiny\\.pl|tiny\\.ly|tiny\\.cc|'\n",
        "            'tcrn\\.ch|ta\\.gd|t\\.co|t\\.cn|su\\.pr|sp2\\.ro|snurl\\.com|snipurl\\.com|snipr\\.com|'\n",
        "            'shrt\\.st|shorturl\\.com|short\\.ie|shorl\\.com|shar\\.es|sameurl\\.com|safe\\.mn|post\\.ly|'\n",
        "            'ping\\.fm|ow\\.ly|om\\.ly|nyti\\.ms|nsfw\\.in|moby\\.to|migre\\.me|lnkd\\.in|linkbun\\.ch|'\n",
        "            'linkbee\\.com|liip\\.to|krunchd\\.com|korta\\.nu|j\\.mp|is\\.gd|hurl\\.me|huff\\.to|goo\\.gl|'\n",
        "            'fwd4\\.me|fff\\.to|ff\\.im|fb\\.me|fav\\.me|eepurl\\.com|doiop\\.com|dlvr\\.it|disq\\.us|'\n",
        "            'digg\\.com|digbig\\.com|decenturl\\.com|cutt\\.us|cot\\.ag|cli\\.gs|clck\\.ru|cl\\.ly|'\n",
        "            'chilp\\.it|budurl\\.com|bit\\.ly|binged\\.it|bacn\\.me|arst\\.ch|alturl\\.com|afx\\.cc|'\n",
        "            'adjix\\.com|adf\\.ly|4sq\\.com|3\\.ly|0rz\\.tw|we\\.tl|ouo\\.io|bfy\\.tw|bit\\.do|'\n",
        "            'bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
        "            'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
        "            'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
        "            'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
        "            'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
        "            'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
        "            'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|tr\\.im|link\\.zip\\.net|shorturl\\.at', url)\n",
        "        if match:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def get_dots_in_hostname(self, url):\n",
        "        \"\"\"Basic idea is that more dots in domain part = Sub Domain and Multi Sub Domains\"\"\"\n",
        "        return urlparse(url).netloc.count(\".\")\n",
        "\n",
        "    def has_at_sign(self, url):\n",
        "        if \"@\" in url:\n",
        "            return 1\n",
        "        return 0\n",
        "\n",
        "    # def has_double_slash(self, url):\n",
        "    #    if \"//\" in urlparse(url).netloc:\n",
        "    #        return 1\n",
        "    #    return 0\n",
        "\n",
        "    def has_double_slash(self, url):\n",
        "        # since the position starts from, we have given 6 and not 7 which is according to the document\n",
        "        list = [x.start(0) for x in re.finditer('//', url)]\n",
        "        if list[len(list)-1] > 6:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def has_hyphen_domain(self, url):\n",
        "        if \"-\" in urlparse(url).netloc:\n",
        "            return 1\n",
        "        return 0\n",
        "\n",
        "    def has_https(self, url):\n",
        "        if urlparse(url).scheme == \"https\":\n",
        "            return 1\n",
        "        return 0\n",
        "\n",
        "    def get_host_length(self, url):\n",
        "        return len(urlparse(url).netloc)\n",
        "\n",
        "    def has_hyphen_or_underscore(self, url):\n",
        "        if (\"_\" in url or \"-\" in url):\n",
        "            return 1\n",
        "        return 0\n",
        "\n",
        "    def get_base_url_length(self, url):\n",
        "        parsedUrl = urlparse(url)\n",
        "        return len(parsedUrl.scheme) + len(parsedUrl.netloc) + len(parsedUrl.path)\n",
        "\n",
        "    def get_feautures_list(self):\n",
        "        return self.feautures\n",
        "\n",
        "    def set_feautures_list(self, url):\n",
        "        self.feautures = [\n",
        "            self.has_ip(url),\n",
        "            self.is_url_short(url),\n",
        "            self.get_dots_in_hostname(url),\n",
        "            self.has_at_sign(url),\n",
        "            self.has_double_slash(url),\n",
        "            self.has_hyphen_domain(url),\n",
        "            self.has_https(url),\n",
        "            self.get_host_length(url),\n",
        "            self.has_hyphen_or_underscore(url),\n",
        "            self.get_base_url_length(url),\n",
        "        ]\n",
        "\n",
        "    def get_feautures_names(self):\n",
        "        \"\"\"Get names of all the methods in the class as a list.\n",
        "        This will be used as column names in the Dataframe.\n",
        "        Doesn't seem to be better way than to call __name__ on each method.\n",
        "        The best would be to somehow automatically call this on all methods in the class.\n",
        "        But I don't know how to do it without overcomplicaitng things.\"\"\"\n",
        "        return [\n",
        "            self.has_ip.__name__,\n",
        "            self.is_url_short.__name__,\n",
        "            self.get_dots_in_hostname.__name__,\n",
        "            self.has_at_sign.__name__,\n",
        "            self.has_double_slash.__name__,\n",
        "            self.has_hyphen_domain.__name__,\n",
        "            self.has_https.__name__,\n",
        "            self.get_host_length.__name__,\n",
        "            self.has_hyphen_or_underscore.__name__,\n",
        "            self.get_base_url_length.__name__,\n",
        "        ]\n",
        "\n",
        "\n",
        "class UrlFeaturesWithLabel(UrlFeautures):\n",
        "    def __init__(self, url: str, label: int):\n",
        "        #self.feautures = self.get_feautures_list(url)\n",
        "        self.set_feautures_list(url, label)\n",
        "\n",
        "    def set_feautures_list(self, url, label):\n",
        "        \"\"\"Setting the feautures, same as base class\n",
        "        and adding the label.\"\"\"\n",
        "        super().set_feautures_list(url)\n",
        "        self.feautures.append(label)\n",
        "\n",
        "    def get_feautures_names(self):\n",
        "        \"\"\"Overriding feauture names and adding the label for clasificaiton\"\"\"\n",
        "        feauture_names = super().get_feautures_names()\n",
        "        feauture_names.append('is_phishing')\n",
        "        print(feauture_names)\n",
        "        return feauture_names\n",
        "\n",
        "\n",
        "class DataSet:\n",
        "    RANDOM_STATE = 12\n",
        "\n",
        "    def __init__(self, legitimate_URLs: pd.DataFrame, phishing_URLs: pd.DataFrame, numberOfSamples: int):\n",
        "        self.legitURLs = legitimate_URLs\n",
        "        self.phishingURLs = phishing_URLs\n",
        "        self.numberOfSamples = numberOfSamples\n",
        "        self.data = self.createDataSet()\n",
        "\n",
        "    def createPhishingDataFrame(self):\n",
        "        phishingFeatures = []\n",
        "        is_phishing = 1\n",
        "\n",
        "        phishurl = self.phishingURLs.sample(\n",
        "            n=self.numberOfSamples, random_state=self.RANDOM_STATE).copy()\n",
        "        phishurl = phishurl.reset_index(drop=True)\n",
        "\n",
        "        for i in range(0, self.numberOfSamples):\n",
        "            url = phishurl['url'][i]\n",
        "            feautureExtraction = UrlFeaturesWithLabel(url, is_phishing)\n",
        "            phishingFeatures.append(feautureExtraction.feautures)\n",
        "\n",
        "        return pd.DataFrame(phishingFeatures, columns=feautureExtraction.get_feautures_names())\n",
        "\n",
        "    def createLegitimateDataFrame(self):\n",
        "        legi_features = []\n",
        "        is_phishing = 0\n",
        "\n",
        "        # the data is asumed to have first column as 'url'\n",
        "        self.legitURLs.columns = ['url']\n",
        "        legiurl = self.legitURLs.sample(\n",
        "            n=self.numberOfSamples, random_state=self.RANDOM_STATE).copy()\n",
        "        legiurl = legiurl.reset_index(drop=True)\n",
        "\n",
        "        for i in range(0, self.numberOfSamples):\n",
        "            url = legiurl['url'][i]\n",
        "            feautureExtraction = UrlFeaturesWithLabel(url, is_phishing)\n",
        "            legi_features.append(feautureExtraction.feautures)\n",
        "\n",
        "        return pd.DataFrame(legi_features, columns=feautureExtraction.get_feautures_names())\n",
        "\n",
        "    def createDataSet(self):\n",
        "        # concat both of the sets\n",
        "        legitimate = self.createLegitimateDataFrame()\n",
        "        phishing = self.createPhishingDataFrame()\n",
        "        return pd.concat([legitimate, phishing]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# initialising it for colab to be avilable outside of this code block\n",
        "urldata = pd.DataFrame()\n",
        "if (__name__ == '__main__'):\n",
        "    # settings to display all columns, used for debuging\n",
        "    pd.set_option(\"display.max_columns\", None)\n",
        "    legitURLs = pd.read_csv(\"/tmp/legitUrls.csv\")\n",
        "    phishingURLs = pd.read_csv(\"/tmp/phishingUrls.csv\")\n",
        "    dataSet = DataSet(legitURLs, phishingURLs, 5000)\n",
        "    urldata = dataSet.data\n"
      ],
      "metadata": {
        "id": "a0OYZ1uiNZsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e8079a-4c06-45fb-8d18-8337a393cb14"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['has_ip', 'is_url_short', 'get_dots_in_hostname', 'has_at_sign', 'has_double_slash', 'has_hyphen_domain', 'has_https', 'get_host_length', 'has_hyphen_or_underscore', 'get_base_url_length', 'is_phishing']\n",
            "['has_ip', 'is_url_short', 'get_dots_in_hostname', 'has_at_sign', 'has_double_slash', 'has_hyphen_domain', 'has_https', 'get_host_length', 'has_hyphen_or_underscore', 'get_base_url_length', 'is_phishing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into a training and a testing dataset.\n",
        "# is this choosing random indexes or do I need to shuffle them???\n",
        "def split_dataset(dataset, test_ratio=0.10):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "train_ds_pd, test_ds_pd = split_dataset(urldata)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyP5w6MePWaO",
        "outputId": "d80b1345-2477-4dd8-8917-baa55c0d8c0c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8980 examples in training, 1020 examples for testing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert pandas dataframe into tensorflow dataset"
      ],
      "metadata": {
        "id": "LM4heW32RIqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=\"is_phishing\")\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=\"is_phishing\")\n"
      ],
      "metadata": {
        "id": "oLdd-0q4Qi3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0dea57f-00f5-40e3-b7c5-ba4c4cb2a2d9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/core.py:1224: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  (dict(dataframe.drop(label, 1)), dataframe[label].values))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model\n",
        "Note:\n",
        "No input features are specified. Therefore, all the columns will be used as input features except for the label. The feature used by the model are shown in the training logs and in the model.summary()"
      ],
      "metadata": {
        "id": "J_nLUd0FREmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Specify the model.\n",
        "model = tfdf.keras.RandomForestModel()\n",
        "\n",
        "# Optionally, add evaluation metrics.\n",
        "model.compile(\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model.\n",
        "# \"sys_pipes\" is optional. It enables the display of the training logs. It doesn't work for some reason.\n",
        "#with sys_pipes():\n",
        "model.fit(x=train_ds)\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY-bBcqjRDPa",
        "outputId": "acfd8f06-82b1-41e7-d85d-65f777a0411c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141/141 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb3d6697b90>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate(test_ds, return_dict=True)\n",
        "print()\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print(f\"{name}: {value:.4f}\")\n"
      ],
      "metadata": {
        "id": "XgC0dCahRsYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19457e0a-d89f-4dab-ab06-ce98e1c58e1e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 0.9706\n",
            "\n",
            "loss: 0.0000\n",
            "accuracy: 0.9706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.summary()\n",
        "#model.make_inspector().variable_importances()\n",
        "#model.make_inspector().evaluation()\n",
        "model.make_inspector().features()\n",
        "\n"
      ],
      "metadata": {
        "id": "eoHiPRvFD4mT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7279ea-23b8-471b-e091-b2cc87960765"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"base_url_length\" (1; #0),\n",
              " \"has_at_sign\" (1; #1),\n",
              " \"has_https\" (1; #2),\n",
              " \"has_hyphen_or_underscore\" (1; #3),\n",
              " \"host_name_length\" (1; #4),\n",
              " \"number_of_dots_in_hostname\" (1; #5)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model, tree_idx=0, max_depth=3)\n"
      ],
      "metadata": {
        "id": "RhIShyTMXx1u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "096d5dda-ef1f-496c-fe84-188192d69906"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_96e867273fbe4d218d157f6f2d854682\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.5001113585746102, 0.49988864142538975], \"num_examples\": 8980.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"get_dots_in_hostname\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.023980815347721823, 0.9760191846522782], \"num_examples\": 417.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"has_hyphen_or_underscore\", \"threshold\": 0.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.04608294930875576, 0.9539170506912442], \"num_examples\": 217.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"get_host_length\", \"threshold\": 20.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 192.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.4, 0.6], \"num_examples\": 25.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"get_base_url_length\", \"threshold\": 74.5}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 200.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.5232979096111176, 0.4767020903888824], \"num_examples\": 8563.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"get_base_url_length\", \"threshold\": 72.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8896702230843841, 0.11032977691561591], \"num_examples\": 4124.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"get_host_length\", \"threshold\": 20.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.1152073732718894, 0.8847926267281107], \"num_examples\": 217.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"has_https\", \"threshold\": 0.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.932684924494497, 0.06731507550550295], \"num_examples\": 3907.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"get_host_length\", \"threshold\": 13.5}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.18292408200045054, 0.8170759179995495], \"num_examples\": 4439.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"has_https\", \"threshold\": 0.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.031426553672316386, 0.9685734463276836], \"num_examples\": 2832.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"get_host_length\", \"threshold\": 11.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.44990665836963284, 0.5500933416303672], \"num_examples\": 1607.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"get_host_length\", \"threshold\": 21.5}}]}]}]}, \"#tree_plot_96e867273fbe4d218d157f6f2d854682\")\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Default TF-serving produces error. Finally found why that's happening. The explanation:\n",
        ">TensorFlow Serving is a serving system for TensorFlow models in production environments. The TF-Serving team publishes a pre-compiled release containing only Core TensorFlow ops.\n",
        "\n",
        ">TensorFlow Decision Forests (TF-DF) models use custom Ops for inference. Therefore, they are not compatible with the pre-compiled releases of TF-Serving. The solution to serve TF-DF models with TF-Serving is to re-compile TF-Serving with TF-DF ops. This document explains how to do so.\n",
        "\n",
        "https://github.com/tensorflow/decision-forests/blob/main/documentation/tensorflow_serving.md"
      ],
      "metadata": {
        "id": "9WQhIpKcuKOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "EFj2W1x9nlr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76bd44f4-5544-4d2c-84c2-daa1e46070f7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = \"/content/gdrive/MyDrive/phishingModelMoreFeautures\"\n",
        "# model_1.save(\"/content/gdrive/MyDrive/firstModelSave\")\n",
        "# Fetch the Keras session and save the model\n",
        "# The signature definition is defined by the input and output tensors,\n",
        "# and stored with the default serving key\n",
        "import tempfile\n",
        "\n",
        "version = 1\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print('export_path = {}\\n'.format(export_path))\n",
        "\n",
        "tf.keras.models.save_model(\n",
        "    model,\n",
        "    export_path,\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        ")\n",
        "\n",
        "print('\\nSaved model:')\n",
        "!ls -l {export_path}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqN7DTUUXjJM",
        "outputId": "504a1498-a6e0-42f5-ecd0-e97a07b80f42"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "export_path = /content/gdrive/MyDrive/phishingModelMoreFeautures/1\n",
            "\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/phishingModelMoreFeautures/1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/phishingModelMoreFeautures/1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved model:\n",
            "total 152\n",
            "drwx------ 2 root root   4096 Mar  7 15:51 assets\n",
            "-rw------- 1 root root   2987 Mar  7 15:51 keras_metadata.pb\n",
            "-rw------- 1 root root 144216 Mar  7 15:51 saved_model.pb\n",
            "drwx------ 2 root root   4096 Mar  7 15:51 variables\n"
          ]
        }
      ]
    }
  ]
}